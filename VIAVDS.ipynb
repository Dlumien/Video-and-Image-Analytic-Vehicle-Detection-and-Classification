{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VIAVDS",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMiP3auf1Hkovs8/BsSCp3x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dlumien/Video-and-Image-Analytic-Vehicle-Detection-and-Classification/blob/main/VIAVDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtmgkQvbYo7R",
        "outputId": "0ac6bcde-e8e0-493e-e9da-4d20f29d0ca0"
      },
      "source": [
        "!git clone https://github.com/Dlumien/Video-and-Image-Analytic-Vehicle-Detection-and-Classification.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Video-and-Image-Analytic-Vehicle-Detection-and-Classification'...\n",
            "remote: Enumerating objects: 68, done.\u001b[K\n",
            "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 68 (delta 6), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (68/68), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_2aYnyBYwql"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "\n",
        "def order_points(pts):\n",
        "    # initialzie a list of coordinates that will be ordered\n",
        "    # such that the first entry in the list is the top-left,\n",
        "    # the second entry is the top-right, the third is the\n",
        "    # bottom-right, and the fourth is the bottom-left\n",
        "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
        "\n",
        "    # the top-left point will have the smallest sum, whereas\n",
        "    # the bottom-right point will have the largest sum\n",
        "    s = pts.sum(axis=1)\n",
        "    rect[0] = pts[np.argmin(s)]\n",
        "    rect[2] = pts[np.argmax(s)]\n",
        "\n",
        "    # now, compute the difference between the points, the\n",
        "    # top-right point will have the smallest difference,\n",
        "    # whereas the bottom-left will have the largest difference\n",
        "    diff = np.diff(pts, axis=1)\n",
        "    rect[1] = pts[np.argmin(diff)]\n",
        "    rect[3] = pts[np.argmax(diff)]\n",
        "\n",
        "    # return the ordered coordinates\n",
        "    return rect\n",
        "\n",
        "\n",
        "def four_point_transform(image, pts):\n",
        "    # obtain a consistent order of the points and unpack them\n",
        "    # individually\n",
        "    rect = order_points(pts)\n",
        "    (tl, tr, br, bl) = rect\n",
        "\n",
        "    # compute the width of the new image, which will be the\n",
        "    # maximum distance between bottom-right and bottom-left\n",
        "    # x-coordiates or the top-right and top-left x-coordinates\n",
        "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
        "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
        "    maxWidth = max(int(widthA), int(widthB))\n",
        "\n",
        "    # compute the height of the new image, which will be the\n",
        "    # maximum distance between the top-right and bottom-right\n",
        "    # y-coordinates or the top-left and bottom-left y-coordinates\n",
        "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
        "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
        "    maxHeight = max(int(heightA), int(heightB))\n",
        "\n",
        "    # now that we have the dimensions of the new image, construct\n",
        "    # the set of destination points to obtain a \"birds eye view\",\n",
        "    # (i.e. top-down view) of the image, again specifying points\n",
        "    # in the top-left, top-right, bottom-right, and bottom-left\n",
        "    # order\n",
        "    dst = np.array([\n",
        "        [0, 0],\n",
        "        [maxWidth - 1, 0],\n",
        "        [maxWidth - 1, maxHeight - 1],\n",
        "        [0, maxHeight - 1]], dtype=\"float32\")\n",
        "\n",
        "    # compute the perspective transform matrix and then apply it\n",
        "    M = cv2.getPerspectiveTransform(rect, dst)\n",
        "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
        "\n",
        "    # return the warped image\n",
        "    return warped\n",
        "\n",
        "\n",
        "def automatic_brightness_and_contrast(image, clip_hist_percent=10):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Calculate grayscale histogram\n",
        "    hist = cv2.calcHist([gray],[0],None,[256],[0,256])\n",
        "    hist_size = len(hist)\n",
        "\n",
        "    # Calculate cumulative distribution from the histogram\n",
        "    accumulator = []\n",
        "    accumulator.append(float(hist[0]))\n",
        "    for index in range(1, hist_size):\n",
        "        accumulator.append(accumulator[index -1] + float(hist[index]))\n",
        "\n",
        "    # Locate points to clip\n",
        "    maximum = accumulator[-1]\n",
        "    clip_hist_percent *= (maximum/100.0)\n",
        "    clip_hist_percent /= 2.0\n",
        "\n",
        "    # Locate left cut\n",
        "    minimum_gray = 0\n",
        "    while accumulator[minimum_gray] < clip_hist_percent:\n",
        "        minimum_gray += 1\n",
        "\n",
        "    # Locate right cut\n",
        "    maximum_gray = hist_size -1\n",
        "    while accumulator[maximum_gray] >= (maximum - clip_hist_percent):\n",
        "        maximum_gray -= 1\n",
        "\n",
        "    # Calculate alpha and beta values\n",
        "    alpha = 255 / (maximum_gray - minimum_gray)\n",
        "    beta = -minimum_gray * alpha\n",
        "\n",
        "    auto_result = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
        "    return auto_result, alpha, beta\n",
        "\n",
        "\n",
        "def detect(img_rgb):\n",
        "\n",
        "    img = img_rgb.copy()\n",
        "    input_height = img_rgb.shape[0]\n",
        "    input_width = img_rgb.shape[1]\n",
        "    hsv_frame = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # yellow color\n",
        "    low_yellow = np.array([110,50,50])\n",
        "    high_yellow = np.array([130,255,255])\n",
        "    yellow_mask = cv2.inRange(hsv_frame, low_yellow, high_yellow)\n",
        "    yellow = cv2.bitwise_and(yellow_mask, yellow_mask, mask=yellow_mask)\n",
        "\n",
        "    cv2.imwrite(\"temp/steps/1_yellow_color_detection.png\", yellow)\n",
        "    # Close morph\n",
        "    k = np.ones((5, 5), np.uint8)\n",
        "    closing = cv2.morphologyEx(yellow, cv2.MORPH_CLOSE, k)\n",
        "\n",
        "    cv2.imwrite(\"temp/steps/2_closing_morphology.png\", closing)\n",
        "    # Detect yellow area\n",
        "    contours, hierarchy = cv2.findContours(closing, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # List of final crops\n",
        "    crops = []\n",
        "\n",
        "    # Loop over contours and find license plates\n",
        "    for cnt in contours:\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "\n",
        "        # Conditions on crops dimensions and area\n",
        "        if h*6 > w > 2 * h and h > 0.1 * w and w * h > input_height * input_width * 0.0001:\n",
        "\n",
        "            # Make a crop from the RGB image, the crop is slided a bit at left to detect bleu area\n",
        "            crop_img = img_rgb[y:y + h, x-round(w/10):x]\n",
        "            crop_img = crop_img.astype('uint8')\n",
        "\n",
        "            # Compute bleu color density at the left of the crop\n",
        "            # Bleu color condition\n",
        "            try:\n",
        "                hsv_frame = cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV)\n",
        "                low_bleu = np.array([0, 0, 140])\n",
        "                high_bleu = np.array([256, 60, 256])\n",
        "                bleu_mask = cv2.inRange(hsv_frame, low_bleu, high_bleu)\n",
        "                bleu_summation = bleu_mask.sum()\n",
        "\n",
        "            except:\n",
        "                bleu_summation = 0\n",
        "\n",
        "            # Condition on bleu color density at the left of the crop\n",
        "            if bleu_summation > 550:\n",
        "\n",
        "                # Compute yellow color density in the crop\n",
        "                # Make a crop from the RGB image\n",
        "                imgray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
        "                crop_img_yellow = img_rgb[y:y + h, x:x+w]\n",
        "                crop_img_yellow = crop_img_yellow.astype('uint8')\n",
        "\n",
        "                # Detect yellow color\n",
        "                hsv_frame = cv2.cvtColor(crop_img_yellow, cv2.COLOR_BGR2HSV)\n",
        "                low_yellow = np.array([110,50,50])\n",
        "                high_yellow = np.array([130,255,255])\n",
        "                yellow_mask = cv2.inRange(hsv_frame, low_yellow, high_yellow)\n",
        "\n",
        "                # Compute yellow density\n",
        "                yellow_summation = yellow_mask.sum()\n",
        "\n",
        "                # Condition on yellow color density in the crop\n",
        "                if yellow_summation > 255*crop_img.shape[0]*crop_img.shape[0]*0.4:\n",
        "\n",
        "                    # Make a crop from the gray image\n",
        "                    crop_gray = imgray[y:y + h, x:x + w]\n",
        "                    crop_gray = crop_gray.astype('uint8')\n",
        "\n",
        "                    # Detect chars inside yellow crop with specefic dimension and area\n",
        "                    th = cv2.adaptiveThreshold(crop_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "                    contours2, hierarchy = cv2.findContours(th, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "                    # Init number of chars\n",
        "                    chars = 0\n",
        "                    for c in contours2:\n",
        "                        area2 = cv2.contourArea(c)\n",
        "                        x2, y2, w2, h2 = cv2.boundingRect(c)\n",
        "                        if w2 * h2 > h * w * 0.01 and h2 > w2 and area2 < h * w * 0.9:\n",
        "                            chars += 1\n",
        "\n",
        "                    # Condition on the number of chars\n",
        "                    if 20 > chars > 4:\n",
        "                        rect = cv2.minAreaRect(cnt)\n",
        "                        box = cv2.boxPoints(rect)\n",
        "                        box = np.int0(box)\n",
        "                        pts = np.array(box)\n",
        "                        warped = four_point_transform(img, pts)\n",
        "                        crops.append(warped)\n",
        "\n",
        "                        # Using cv2.putText() method\n",
        "                        img_rgb = cv2.putText(img_rgb, 'License Plate', (x-20, y), cv2.FONT_HERSHEY_SIMPLEX,1, (0, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "                        cv2.drawContours(img_rgb, [box], 0, (0, 0, 255), 2)\n",
        "\n",
        "    return img_rgb, crops\n",
        "\n",
        "\n",
        "def detect_belg(src):\n",
        "    img, alpha, beta = automatic_brightness_and_contrast(src)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    ret, th = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    contours, hierarchy = cv2.findContours(th, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    crops = []\n",
        "    for cnt in contours:\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "\n",
        "        if h * 6 > w > 2 * h and h > 0.1 * w and w * h > img.shape[0] * img.shape[1] * 0.0001:\n",
        "            crop = th[y:y + h, x:x + w]\n",
        "\n",
        "            # Compute sum of white pixels\n",
        "            white_summation = crop.sum()\n",
        "            if white_summation > w * h * 0.4 * 255:\n",
        "                # Compute sum of red pixel\n",
        "                crop = img[y:y + h, x:x + w]\n",
        "                crop_img = crop.astype('uint8')\n",
        "                hsv = cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV)\n",
        "                lower_red = np.array([160, 100, 100])\n",
        "                upper_red = np.array([179, 255, 255])\n",
        "                red_mask = cv2.inRange(hsv, lower_red, upper_red)\n",
        "                red_summation = red_mask.sum()\n",
        "\n",
        "                if red_summation > 510:\n",
        "                    crop_img = img[y:y + h, x - round(w / 10):x + w]\n",
        "                    crop_img = crop_img.astype('uint8')\n",
        "                    hsv = cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV)\n",
        "                    low_bleu = np.array([100, 150, 0])\n",
        "                    high_bleu = np.array([140, 255, 255])\n",
        "                    bleu_mask = cv2.inRange(hsv, low_bleu, high_bleu)\n",
        "                    bleu_summation = bleu_mask.sum()\n",
        "\n",
        "                    if bleu_summation > 255:\n",
        "\n",
        "                        crop = gray[y:y + h, x:x + w]\n",
        "                        crop_img = crop.astype('uint8')\n",
        "                        th2 = cv2.adaptiveThreshold(crop_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,\n",
        "                                                    11, 2)\n",
        "\n",
        "                        contours2, hierarchy = cv2.findContours(th2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "                        j = 0\n",
        "                        for c in contours2:\n",
        "                            area2 = cv2.contourArea(c)\n",
        "                            x2, y2, w2, h2 = cv2.boundingRect(c)\n",
        "                            if w2 * h2 > h * w * 0.01 and h2 > w2 and area2 < h * w * 0.9:\n",
        "                                j += 1\n",
        "\n",
        "                        if 12 > j > 4:\n",
        "                            rect = cv2.minAreaRect(cnt)\n",
        "                            box = cv2.boxPoints(rect)\n",
        "                            box = np.int0(box)\n",
        "                            pts = np.array(box)\n",
        "                            warped = four_point_transform(src, pts)\n",
        "                            crops.append(warped)\n",
        "\n",
        "                            cv2.drawContours(src, [box], 0, (0, 255, 0), 2)\n",
        "    return src, crops\n",
        "\n",
        "\n",
        "def process(src):\n",
        "\n",
        "    # Brigthness and contrast adjustment\n",
        "    cv2.imwrite(\"temp/steps/3_detected_plate.png\", src)\n",
        "    adjusted, a, b = automatic_brightness_and_contrast(src)\n",
        "    cv2.imwrite(\"temp/steps/4_Brigthness_contrast_adjustment.png\", adjusted)\n",
        "    # BGR to gray\n",
        "    gray = cv2.cvtColor(adjusted, cv2.COLOR_BGR2GRAY)\n",
        "    cv2.imwrite(\"temp/steps/5_gray.png\", gray)\n",
        "    # Binary thresh\n",
        "    #ret, th = cv2.threshold(gray, 140, 255, cv2.THRESH_BINARY)\n",
        "    ret, th = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    cv2.imwrite(\"temp/steps/6_threshold.png\", th)\n",
        "    return th\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovH_7smBY3UU"
      },
      "source": [
        "import cv2\n",
        "import numpy\n",
        "import os\n",
        "import glob\n",
        "import sys\n",
        "import time\n",
        "\n",
        "def detect_image(input_image):\n",
        "    start = time.time()\n",
        "    try:\n",
        "        os.mkdir('temp')\n",
        "    except:\n",
        "        files = glob.glob('tmp')\n",
        "        for f in files:\n",
        "            os.remove(f)\n",
        "\n",
        "    detection, crops = detect(input_image)\n",
        "\n",
        "    i = 1\n",
        "    for crop in crops:\n",
        "\n",
        "        crop = process(crop)\n",
        "\n",
        "        cv2.imwrite('temp/crop' + str(i) + '.jpg', crop)\n",
        "        # text = pytesseract.image_to_string(Image.open('temp/crop1.jpg'))\n",
        "        i += 1\n",
        "    cv2.imwrite('temp/detection.jpg', detection)\n",
        "    finish = time.time()\n",
        "    print('Detection processed in >>>>>>  '+ str(finish-start))\n",
        "\n",
        "def detect_video(video_file_name):\n",
        "    cap = cv2.VideoCapture(video_file_name)\n",
        "\n",
        "    if cap.isOpened() == False:\n",
        "        print(\"Error opening video stream or file\")\n",
        "\n",
        "    while (cap.isOpened()):\n",
        "        # Capture frame-by-frame\n",
        "        ret, frame = cap.read()\n",
        "        if ret == True:\n",
        "\n",
        "            frame, crop = detect(frame)\n",
        "            # Display the resulting frame\n",
        "\n",
        "            cv2.putText(frame, 'Press \\'Q\\' to exit !',(50, 50),cv2.FONT_HERSHEY_SIMPLEX,1,(0, 0, 255), 2)\n",
        "            cv2.imshow('Frame', frame)\n",
        "\n",
        "            # Press Q on keyboard to  exit\n",
        "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "                break\n",
        "\n",
        "        # Break the loop\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    # When everything done, release the video capture object\n",
        "    cap.release()\n",
        "\n",
        "    # Closes all the frames\n",
        "    cv2.destroyAllWindows()\n",
        "\t"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gr7Rn576Y9UO",
        "outputId": "a5d7d3aa-6b22-4011-ff20-7d6ca4d1125b"
      },
      "source": [
        "image = cv2.imread('Video-and-Image-Analytic-Vehicle-Detection-and-Classification/Sample/9.jpg')\n",
        "detect_image(image)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Detection processed in >>>>>>  0.11920905113220215\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}